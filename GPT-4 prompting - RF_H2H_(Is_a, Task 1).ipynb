{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac90fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import openai\n",
    "import requests\n",
    "import json\n",
    "from transformers import set_seed\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0170a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load task 1 positive and negative datasets, select 'is_a' links, shuffle\n",
    "\n",
    "df_positive = pd.read_csv('data/df_positive_test.csv', index_col=0)\n",
    "df_negative = pd.read_csv('data/df_negative_1_test.csv', index_col=0)\n",
    "\n",
    "df_positive_is_a = df_positive[df_positive.link == 'is_a'].sample(frac=1, random_state = 101)\n",
    "df_negative_is_a = df_negative[df_negative.link == 'is_a'].sample(frac=1, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc835e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cc/rm73tz993mjcpf7dpbrlh77w0000gn/T/ipykernel_56255/2153189852.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pos_50['y'] = 1\n",
      "/var/folders/cc/rm73tz993mjcpf7dpbrlh77w0000gn/T/ipykernel_56255/2153189852.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_neg_50['y'] = 0\n"
     ]
    }
   ],
   "source": [
    "# Split pos and neg dfs into example and prompt triples\n",
    "\n",
    "# Prompt (50 pos, 50 neg)\n",
    "df_pos_50 = df_positive_is_a.iloc[:50]\n",
    "df_neg_50 = df_negative_is_a.iloc[:50]\n",
    "df_pos_50['y'] = 1\n",
    "df_neg_50['y'] = 0\n",
    "\n",
    "# Example (Remainder)\n",
    "df_pos_example = df_positive_is_a.iloc[50:]\n",
    "df_neg_example = df_negative_is_a.iloc[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbddd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate, shuffle, export test sample\n",
    "\n",
    "df_prompting_test = pd.concat([df_pos_50, df_neg_50], axis=0).sample(frac=1, random_state = 101)\n",
    "df_prompting_test.to_csv('prompting_test_Task_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4537338",
   "metadata": {},
   "source": [
    "# GPT-4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876c4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "API_ENDPOINT = \"https://api.openai.com/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba9f1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to submit prompt \n",
    "\n",
    "def generate_chat_completion(messages, model=\"gpt-4\", temperature=0, max_tokens=10):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "\n",
    "    if max_tokens is not None:\n",
    "        data[\"max_tokens\"] = max_tokens\n",
    "\n",
    "    response = requests.post(API_ENDPOINT, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd89627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dataframe to store positive and negative example triples, triple for model to classify\n",
    "# response returned and ground-truth label \n",
    "\n",
    "prediction_table = pd.DataFrame(columns=['Pos_Ex_1', 'Pos_Ex_2', 'Pos_Ex_3', 'Neg_Ex_1', 'Neg_Ex_2', \n",
    "                                         'Neg_Ex_3','Prompt', 'Response', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85733048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to randomly select 3x positive and 3x negative example triples, a randomly selected positive or \n",
    "# negative triple to classify, generate/submit prompt and keep track of results\n",
    "\n",
    "def run_prompts(run_no):\n",
    "    \n",
    "    global prediction_table\n",
    "    \n",
    "    pos_examples = []\n",
    "    neg_examples = []\n",
    "    new_row = {}\n",
    "    \n",
    "    prompt = df_prompting_test.iloc[run_no]\n",
    "    new_row['Label'] = prompt['y']\n",
    "    prompt_triple = prompt['head_name'] + \" \" + \" \".join(prompt['link'].split('_')) + \" \" + prompt['tail_name']\n",
    "    new_row['Prompt'] = prompt_triple\n",
    "    \n",
    "    samp_pos = df_pos_example.sample(3)\n",
    "    PT1 = samp_pos.iloc[0,1] + \" \" + \" \".join(samp_pos.iloc[0,2].split('_')) + \" \" + samp_pos.iloc[0,4]\n",
    "    PT2 = samp_pos.iloc[1,1] + \" \" + \" \".join(samp_pos.iloc[1,2].split('_')) + \" \" + samp_pos.iloc[1,4]\n",
    "    PT3 = samp_pos.iloc[2,1] + \" \" + \" \".join(samp_pos.iloc[2,2].split('_')) + \" \" + samp_pos.iloc[2,4]\n",
    "    pos_examples.extend([PT1, PT2, PT3])\n",
    "    \n",
    "    samp_neg = df_neg_example.sample(3)\n",
    "    NT1 = samp_neg.iloc[0,1] + \" \" + \" \".join(samp_neg.iloc[0,2].split('_')) + \" \" + samp_neg.iloc[0,4]\n",
    "    NT2 = samp_neg.iloc[1,1] + \" \" + \" \".join(samp_neg.iloc[1,2].split('_')) + \" \" + samp_neg.iloc[1,4]\n",
    "    NT3 = samp_neg.iloc[2,1] + \" \" + \" \".join(samp_neg.iloc[2,2].split('_')) + \" \" + samp_neg.iloc[2,4]\n",
    "    neg_examples.extend([NT1, NT2, NT3])\n",
    "    \n",
    "    for i in range(3):\n",
    "        new_row[f\"Pos_Ex_{i+1}\"] = pos_examples[i]\n",
    "        new_row[f\"Neg_Ex_{i+1}\"] = neg_examples[i]\n",
    "    \n",
    "    \n",
    "    full_prompt = f\"\"\"\n",
    "    Your task is to classify triples as True or False. If you do not know the answer, state 'I don't know.'\n",
    "\n",
    "    <triple>: {neg_examples[0]}\n",
    "    <classification>: False\n",
    "    \n",
    "    <triple>: {pos_examples[0]}\n",
    "    <classification>: True\n",
    "    \n",
    "    <triple>: {neg_examples[1]}\n",
    "    <classification>: False\n",
    "\n",
    "    <triple>: {pos_examples[1]}\n",
    "    <classification>: True\n",
    "\n",
    "    <triple>: {pos_examples[2]}\n",
    "    <classification>: True\n",
    "\n",
    "    <triple>: {neg_examples[2]}\n",
    "    <classification>: False\n",
    "\n",
    "    <triple>: {prompt_triple}\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": full_prompt}]\n",
    "    \n",
    "    response_text = generate_chat_completion(messages)\n",
    "    new_row['Response'] = response_text\n",
    "    \n",
    "    prediction_table = prediction_table.append(new_row, ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4990a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(352)\n",
    "\n",
    "for i in range(100):\n",
    "    run_prompts(run_no=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08f03f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos_Ex_1</th>\n",
       "      <th>Pos_Ex_2</th>\n",
       "      <th>Pos_Ex_3</th>\n",
       "      <th>Neg_Ex_1</th>\n",
       "      <th>Neg_Ex_2</th>\n",
       "      <th>Neg_Ex_3</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "      <th>Label</th>\n",
       "      <th>Resp_numeric</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>norsolorinic acid anthrone is a polyketide</td>\n",
       "      <td>N-[(3R,4R,5S,6R)-5-[(2S,3R,4R,5S,6R)-3-Acetami...</td>\n",
       "      <td>4-hexyl-3-thiophen-2-yl-1H-1,2,4-triazole-5-th...</td>\n",
       "      <td>aryne is a benzenesulfonic acids</td>\n",
       "      <td>Avenestergenin A2 is a 1-[(3S,9S,10S)-12-[(2R)...</td>\n",
       "      <td>[2-hydroxy-5-(prop-2-en-1-yl)phenyl]oxidanesul...</td>\n",
       "      <td>N-[(2S,3S,6R)-6-[2-(ethylsulfonylamino)ethyl]-...</td>\n",
       "      <td>&lt;classification&gt;: False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>His-Ser-Asp is a oligopeptide</td>\n",
       "      <td>benazepril is a lactam</td>\n",
       "      <td>lignin cw compound-134 is a phenols</td>\n",
       "      <td>beta-glucosyl 6-beta-glucosyloxy-indole-3-carb...</td>\n",
       "      <td>Gly-Arg-Leu is a Glu-Asp-Tyr</td>\n",
       "      <td>N-[(2S,3R,4R,5R,6R)-6-[[(2R,3R,4R,5S,6R)-3-Ace...</td>\n",
       "      <td>N-(3,4-dimethoxyphenyl)-6-phenyl-4-thieno[2,3-...</td>\n",
       "      <td>&lt;classification&gt;: False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-ethylacrylic acid is a alpha,beta-unsaturate...</td>\n",
       "      <td>(S)-bitolterol is a bitolterol</td>\n",
       "      <td>2-O-(6-phosphono-alpha-D-mannosyl)-D-glyceric ...</td>\n",
       "      <td>Mycosanoic acid (C24) is a N-[(5S,6S,9S)-8-[cy...</td>\n",
       "      <td>31-demethylbuxaminol is a 5-(4-methoxyphenyl)-...</td>\n",
       "      <td>diacylglycerol 38:2 is a Putaminoxin</td>\n",
       "      <td>cobalt-precorrin-6B is a cobalt corrinoid</td>\n",
       "      <td>&lt;classification&gt;: True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>platensic acid methyl ester is a methyl ester</td>\n",
       "      <td>7-O-[alpha-L-rhamnosyl-(1-&gt;2)-beta-D-glucosyl]...</td>\n",
       "      <td>phytol is a diterpenoid</td>\n",
       "      <td>Adrenochrome o-semiquinone is a 2-(2-chlorophe...</td>\n",
       "      <td>BMS-453 is a pirazofurin</td>\n",
       "      <td>19-Methoxypomolic acid 3-arabinoside is a alph...</td>\n",
       "      <td>2-methoxyethyl 2-(4-tert-butylphenyl)-2-cyano-...</td>\n",
       "      <td>&lt;classification&gt;: False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N-acyl-O-(3-sn-phosphatidyl)-L-serine is a L-s...</td>\n",
       "      <td>idrocilamide is a cinnamamides</td>\n",
       "      <td>N-[[[(2-hydroxyphenyl)-oxomethyl]hydrazo]-sulf...</td>\n",
       "      <td>noreugenin(1-) is a 24-methylcholesta-5,24-die...</td>\n",
       "      <td>iron(2+) sulfides is a phosphatidylinositol 40...</td>\n",
       "      <td>N-[(2R,3R,4R,5S,6R)-2-[(2R,3S,4R,5S)-4-[(2S,3R...</td>\n",
       "      <td>1-(4-fluorophenyl)-3-[(3S,9R,10R)-12-[(2R)-1-h...</td>\n",
       "      <td>&lt;classification&gt;: False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Pos_Ex_1  \\\n",
       "0         norsolorinic acid anthrone is a polyketide   \n",
       "1                      His-Ser-Asp is a oligopeptide   \n",
       "2  2-ethylacrylic acid is a alpha,beta-unsaturate...   \n",
       "3      platensic acid methyl ester is a methyl ester   \n",
       "4  N-acyl-O-(3-sn-phosphatidyl)-L-serine is a L-s...   \n",
       "\n",
       "                                            Pos_Ex_2  \\\n",
       "0  N-[(3R,4R,5S,6R)-5-[(2S,3R,4R,5S,6R)-3-Acetami...   \n",
       "1                             benazepril is a lactam   \n",
       "2                     (S)-bitolterol is a bitolterol   \n",
       "3  7-O-[alpha-L-rhamnosyl-(1->2)-beta-D-glucosyl]...   \n",
       "4                     idrocilamide is a cinnamamides   \n",
       "\n",
       "                                            Pos_Ex_3  \\\n",
       "0  4-hexyl-3-thiophen-2-yl-1H-1,2,4-triazole-5-th...   \n",
       "1                lignin cw compound-134 is a phenols   \n",
       "2  2-O-(6-phosphono-alpha-D-mannosyl)-D-glyceric ...   \n",
       "3                            phytol is a diterpenoid   \n",
       "4  N-[[[(2-hydroxyphenyl)-oxomethyl]hydrazo]-sulf...   \n",
       "\n",
       "                                            Neg_Ex_1  \\\n",
       "0                   aryne is a benzenesulfonic acids   \n",
       "1  beta-glucosyl 6-beta-glucosyloxy-indole-3-carb...   \n",
       "2  Mycosanoic acid (C24) is a N-[(5S,6S,9S)-8-[cy...   \n",
       "3  Adrenochrome o-semiquinone is a 2-(2-chlorophe...   \n",
       "4  noreugenin(1-) is a 24-methylcholesta-5,24-die...   \n",
       "\n",
       "                                            Neg_Ex_2  \\\n",
       "0  Avenestergenin A2 is a 1-[(3S,9S,10S)-12-[(2R)...   \n",
       "1                       Gly-Arg-Leu is a Glu-Asp-Tyr   \n",
       "2  31-demethylbuxaminol is a 5-(4-methoxyphenyl)-...   \n",
       "3                           BMS-453 is a pirazofurin   \n",
       "4  iron(2+) sulfides is a phosphatidylinositol 40...   \n",
       "\n",
       "                                            Neg_Ex_3  \\\n",
       "0  [2-hydroxy-5-(prop-2-en-1-yl)phenyl]oxidanesul...   \n",
       "1  N-[(2S,3R,4R,5R,6R)-6-[[(2R,3R,4R,5S,6R)-3-Ace...   \n",
       "2               diacylglycerol 38:2 is a Putaminoxin   \n",
       "3  19-Methoxypomolic acid 3-arabinoside is a alph...   \n",
       "4  N-[(2R,3R,4R,5S,6R)-2-[(2R,3S,4R,5S)-4-[(2S,3R...   \n",
       "\n",
       "                                              Prompt                 Response  \\\n",
       "0  N-[(2S,3S,6R)-6-[2-(ethylsulfonylamino)ethyl]-...  <classification>: False   \n",
       "1  N-(3,4-dimethoxyphenyl)-6-phenyl-4-thieno[2,3-...  <classification>: False   \n",
       "2          cobalt-precorrin-6B is a cobalt corrinoid   <classification>: True   \n",
       "3  2-methoxyethyl 2-(4-tert-butylphenyl)-2-cyano-...  <classification>: False   \n",
       "4  1-(4-fluorophenyl)-3-[(3S,9R,10R)-12-[(2R)-1-h...  <classification>: False   \n",
       "\n",
       "  Label  Resp_numeric  Correct  \n",
       "0     1           0.0        0  \n",
       "1     1           0.0        0  \n",
       "2     1           1.0        1  \n",
       "3     0           0.0        1  \n",
       "4     0           0.0        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_table.loc[prediction_table['Response'].str.contains('True'),'Resp_numeric'] = 1\n",
    "prediction_table.loc[prediction_table['Response'].str.contains('False'),'Resp_numeric'] = 0\n",
    "prediction_table['Resp_numeric'] = prediction_table['Resp_numeric'].fillna(2)\n",
    "prediction_table['Correct'] = np.where(prediction_table['Label'] == prediction_table['Resp_numeric'], 1,0)\n",
    "\n",
    "prediction_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fac6e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number correct: 85\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "# Display number and percentage correct \n",
    "\n",
    "print(f\"Number correct: {prediction_table.Correct.sum()}\")\n",
    "acc = prediction_table.Correct.sum()/len(prediction_table)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c86474bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "1\n",
      "46\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "tp = len(prediction_table[(prediction_table.Resp_numeric==1) & (prediction_table.Correct==1)])\n",
    "fp = len(prediction_table[(prediction_table.Resp_numeric==1) & (prediction_table.Correct==0)])\n",
    "tn = len(prediction_table[(prediction_table.Resp_numeric==0) & (prediction_table.Correct==1)])\n",
    "fn = len(prediction_table[(prediction_table.Resp_numeric==0) & (prediction_table.Correct==0)])\n",
    "\n",
    "print(tp)\n",
    "print(fp)\n",
    "print(tn)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc55a6a2",
   "metadata": {},
   "source": [
    "# Random forest models\n",
    "\n",
    "## Random embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8de8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('prompting_test_Task_1', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fe39432",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/rf_random_len_task1.joblib'\n",
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e59f1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load emb_dict\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "with open('embeddings/random.pkl','rb') as f:\n",
    "    emb_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fc97362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vec(text, emb_dict):\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    vectors = []\n",
    "    vec_centroid = []\n",
    "    for i in tokens:\n",
    "        if len(i) >=3:\n",
    "            vec = emb_dict.get(i)\n",
    "            if vec is not None:\n",
    "                vectors.append(vec)\n",
    "    if vectors:\n",
    "        vec_centroid = np.mean(vectors, axis = 0)\n",
    "        return vec_centroid\n",
    "    else:\n",
    "        for i in tokens:\n",
    "            vec = emb_dict.get(i)\n",
    "            if vec is not None:\n",
    "                vectors.append(vec)\n",
    "        vec_centroid = np.mean(vectors, axis = 0)\n",
    "        return vec_centroid\n",
    "\n",
    "def link_to_vec(text, emb_dict):\n",
    "    vectors = []\n",
    "    vec_centroid = []\n",
    "    items = text.split('_')\n",
    "    for item in items:\n",
    "        tokens = tokenizer.tokenize(item.lower())        \n",
    "        for i in tokens:\n",
    "            vec = emb_dict.get(i)\n",
    "            if vec is not None:\n",
    "                vectors.append(vec)\n",
    "    if vectors:\n",
    "        vec_centroid = np.mean(vectors, axis = 0)\n",
    "        return vec_centroid\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5157cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['head_emb'] = df_test['head_name'].map(lambda text: text_to_vec(text, emb_dict))\n",
    "df_test['link_emb'] = df_test['link'].map(lambda text: link_to_vec(text, emb_dict))\n",
    "df_test['tail_emb'] = df_test['tail_name'].map(lambda text: text_to_vec(text, emb_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "268dfbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['X'] = df_test['head_emb'].apply(lambda x: x.tolist()) + df_test['link_emb'].apply(lambda x: x.tolist()) + df_test['tail_emb'].apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf7f2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9792    0.9400    0.9592        50\n",
      "           1     0.9423    0.9800    0.9608        50\n",
      "\n",
      "    accuracy                         0.9600       100\n",
      "   macro avg     0.9607    0.9600    0.9600       100\n",
      "weighted avg     0.9607    0.9600    0.9600       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test['X'].to_list()\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_test = np.array(df_test['y'])\n",
    "y_pred = model.predict(X_test)\n",
    "df_test['y_pred'] = y_pred\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca95872",
   "metadata": {},
   "source": [
    "## Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c0a7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/rf_glove_len_task1.joblib'\n",
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15d5c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load emb_dict\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "with open('embeddings/glove_random.pkl','rb') as f:\n",
    "    emb_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cbbcd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('prompting_test_Task_1', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26413590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['head_emb'] = df_test['head_name'].map(lambda text: text_to_vec(text, emb_dict))\n",
    "df_test['link_emb'] = df_test['link'].map(lambda text: link_to_vec(text, emb_dict))\n",
    "df_test['tail_emb'] = df_test['tail_name'].map(lambda text: text_to_vec(text, emb_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e9fba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['X'] = df_test['head_emb'].apply(lambda x: x.tolist()) + df_test['link_emb'].apply(lambda x: x.tolist()) + df_test['tail_emb'].apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec420f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9583    0.9200    0.9388        50\n",
      "           1     0.9231    0.9600    0.9412        50\n",
      "\n",
      "    accuracy                         0.9400       100\n",
      "   macro avg     0.9407    0.9400    0.9400       100\n",
      "weighted avg     0.9407    0.9400    0.9400       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test['X'].to_list()\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_test = np.array(df_test['y'])\n",
    "y_pred = model.predict(X_test)\n",
    "df_test['y_pred'] = y_pred\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74199ac5",
   "metadata": {},
   "source": [
    "## Pubmed from Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf4f6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/rf_pubmedfromglove_len_task1.joblib'\n",
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9150def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load emb_dict\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "with open('embeddings/pubmed_fromGlove_random.pkl','rb') as f:\n",
    "    emb_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb870e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('prompting_test_Task_1', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71cfe5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['head_emb'] = df_test['head_name'].map(lambda text: text_to_vec(text, emb_dict))\n",
    "df_test['link_emb'] = df_test['link'].map(lambda text: link_to_vec(text, emb_dict))\n",
    "df_test['tail_emb'] = df_test['tail_name'].map(lambda text: text_to_vec(text, emb_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f275b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['X'] = df_test['head_emb'].apply(lambda x: x.tolist()) + df_test['link_emb'].apply(lambda x: x.tolist()) + df_test['tail_emb'].apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad7b1237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9792    0.9400    0.9592        50\n",
      "           1     0.9423    0.9800    0.9608        50\n",
      "\n",
      "    accuracy                         0.9600       100\n",
      "   macro avg     0.9607    0.9600    0.9600       100\n",
      "weighted avg     0.9607    0.9600    0.9600       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test['X'].to_list()\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_test = np.array(df_test['y'])\n",
    "y_pred = model.predict(X_test)\n",
    "df_test['y_pred'] = y_pred\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b6c34",
   "metadata": {},
   "source": [
    "##  Pubmed from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df3e3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/rf_pubmedfromscratch_len_task1.joblib'\n",
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2c14d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load emb_dict\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "with open('embeddings/pubmed_fromScratch_random.pkl','rb') as f:\n",
    "    emb_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb8f6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('prompting_test_Task_1', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eae18cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['head_emb'] = df_test['head_name'].map(lambda text: text_to_vec(text, emb_dict))\n",
    "df_test['link_emb'] = df_test['link'].map(lambda text: link_to_vec(text, emb_dict))\n",
    "df_test['tail_emb'] = df_test['tail_name'].map(lambda text: text_to_vec(text, emb_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e82a783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['X'] = df_test['head_emb'].apply(lambda x: x.tolist()) + df_test['link_emb'].apply(lambda x: x.tolist()) + df_test['tail_emb'].apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1717536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9792    0.9400    0.9592        50\n",
      "           1     0.9423    0.9800    0.9608        50\n",
      "\n",
      "    accuracy                         0.9600       100\n",
      "   macro avg     0.9607    0.9600    0.9600       100\n",
      "weighted avg     0.9607    0.9600    0.9600       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test['X'].to_list()\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_test = np.array(df_test['y'])\n",
    "y_pred = model.predict(X_test)\n",
    "df_test['y_pred'] = y_pred\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b10c0",
   "metadata": {},
   "source": [
    "## Biowordvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d20e4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/rf_Biowordvec_len_task1.joblib'\n",
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6f20301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load emb_dict\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "with open('embeddings/bio_random_extrinsic.pkl','rb') as f:\n",
    "    emb_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0deccb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('prompting_test_Task_1', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77da8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['head_emb'] = df_test['head_name'].map(lambda text: text_to_vec(text, emb_dict))\n",
    "df_test['link_emb'] = df_test['link'].map(lambda text: link_to_vec(text, emb_dict))\n",
    "df_test['tail_emb'] = df_test['tail_name'].map(lambda text: text_to_vec(text, emb_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f1e67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['X'] = df_test['head_emb'].apply(lambda x: x.tolist()) + df_test['link_emb'].apply(lambda x: x.tolist()) + df_test['tail_emb'].apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bcbe86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9592    0.9400    0.9495        50\n",
      "           1     0.9412    0.9600    0.9505        50\n",
      "\n",
      "    accuracy                         0.9500       100\n",
      "   macro avg     0.9502    0.9500    0.9500       100\n",
      "weighted avg     0.9502    0.9500    0.9500       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test['X'].to_list()\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_test = np.array(df_test['y'])\n",
    "y_pred = model.predict(X_test)\n",
    "df_test['y_pred'] = y_pred\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2836af",
   "metadata": {},
   "source": [
    "## PubmedBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a87da38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilygroves/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/emilygroves/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "filename = 'models/rf_bert_pubmed.joblib'\n",
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90e97403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load pubmed bert embeddings - dict key:node/link, value:embeddings\n",
    "with open('embeddings/id2bert_pubmed.pkl','rb') as f:\n",
    "    dict_id2bert = pickle.load(f)\n",
    "\n",
    "with open('embeddings/link2bert_pubmed.pkl','rb') as f:\n",
    "    dict_link2bert = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07f473d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('prompting_test_Task_1', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7383c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['head_emb'] = df_test['head_id'].map(dict_id2bert)\n",
    "df_test['link_emb'] = df_test['link'].map(dict_link2bert)\n",
    "df_test['tail_emb'] = df_test['tail_id'].map(dict_id2bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67d51fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test done\n"
     ]
    }
   ],
   "source": [
    "df_test['X'] = df_test['head_emb'] + df_test['link_emb'] + df_test['tail_emb']\n",
    "print(\"test done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b6df533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9783    0.9000    0.9375        50\n",
      "           1     0.9074    0.9800    0.9423        50\n",
      "\n",
      "    accuracy                         0.9400       100\n",
      "   macro avg     0.9428    0.9400    0.9399       100\n",
      "weighted avg     0.9428    0.9400    0.9399       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test['X'].to_list()\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_test = np.array(df_test['y'])\n",
    "y_pred = model.predict(X_test)\n",
    "df_test['y_pred'] = y_pred\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc43842b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
